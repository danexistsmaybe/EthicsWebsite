---
title: "Blog 4: Generative AI and Its Machinations"
date: 2025-09-30
permalink: /posts/2025/30/blog-post-4/
tags:
  - AI
  - generative
  - machine learning
---

<style>
	.serif, #serif, h1, h2, h3, h4, h5, h6, h7, h8, h9, p, meta, li {
		font-family: Georgia, "Times New Roman", Times, serif;
	}
</style>


*What are the limits of generative AI?*

**Publication**  
[How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

<hr style="background-color: #000; border: none; height: 2px">

## Brief Summary (1-2 Sentences)
This case study focuses on de-mystifying generative AI by explaining how it works. Then, it goes on to discuss its limits (where it fails), and, finally, finishes by describing some of its negative impacts on society.

## Discussion: The use of creative work for training
**"Generative AI is built using the creative output of journalists, writers, photographers, artists, and others — generally without consent, credit, or compensation. Discuss the ethics of this practice."**

I see several legitimate ways of responding to the issue of intellectual ownership over training data. The pro-AI executive will say that this use of material for learning is like any human who learns through observation. If a creative work is publically available to observe, then it is generally accepted that a human artist may use that image as a reference or inspiration for their own budding talent, as long as they are synthesizing what they get from that piece of art into something else: why not, then, a machine? On the other hand, the frustrated creative might point to the actual structure of these models: through "learning," they literally incorporate the information they consume into their parameters. From this perspective, human and machine learning are not comparable because the machine directly plagiarizes art into a high-dimensional vector space. 

However, these arguments feel primarily philophical. The material reality of the situation is that generative AI poses a threat to the creative professions in a way that one human trying to learn a craft does not. Even if it were possible to enforce a rule requiring payment to artists for the use of their art in training, it would hardly solve anything. In other words, the issue, ethically speaking, is existential in nature.

**"How can those who want to change the system go about doing so? Can the market solve the problem, such as through licensing agreements between publishers and AI companies? What about copyright law — either interpreting existing law or by updating it? What other policy interventions might be helpful?"**

Given that the problem is the potential dissolution of the artist career, the market cannot solve it. From the perspective of the market, which is motivated solely by economic terms, the category of 'artist' simply becomes obsolete. In the pursuit of a more productive way of fulfilling society's desire to consume art, it is happy to leave artists behind. Copyright law could slow things down in a meaningful way; creating a new legal use category of 'training ML models' and requiring consent for this category of use would make it far more difficult for AI companies to feel comfortable scraping large, uncurated datasets. Yet, the law cannot be absolute, and there is strong motivation to keep it weak. The fact of the matter is that all progress in generative AI works towards the removal of human artists from the economy, and progress probably won't be entirely stopped by the law. 

As Charli xcx puts it, "the apple's rotten right to the core:" the ethical problem with generative AI stems from the system it exists within. Until generative AI -- a means of production -- rests firmly in the hands of the artist working class, it will continue to work towards their destruction.

## New Discussion Question
**Even if laws were put in place to protect intellectual proporty, AI companies are allowed to operate opaquely in order to protect them from their competition. What regulations in regards to transparancy would be required in order to truly keep these companies accountable and prevent the misuse of generative AI?**

I chose this question because I feel that most of the problems discussed in the article are also dependent on transparacy issues. This is also a point that will make AI regulation hotly contested as AI companies will claim they need the secrecy to protect their interests, and then sue the government. 

## Reflection
I didn't find this case study to be very useful in demystifying AI. Explanations like this one get thrown around all the time, so it's hard to imagine anybody finding out something new about the inner workings of modern machine learning models. Overall, this case study served as general-purpose practice for writing about ethical issues in regards to AI.