---
title: "Blog 3: Exceptions to Data Driven Decisions"
date: 2025-09-25
permalink: /posts/2025/21/blog-post-2/
tags:
  - ai
  - decision making
  - exceptions
---

<style>
	.serif, #serif, h1, h2, h3, h4, h5, h6, h7, h8, h9, p, meta, li {
		font-family: Georgia, "Times New Roman", Times, serif;
	}
</style>


*Data-driven decision making can be highly accurate and convenient, but there will always be exceptions. How, then, should these decisions be made?*

**Publication**  
[The Right to Be an Exception to a Data-Driven Rule](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)

<hr style="background-color: #000; border: none; height: 2px">

## Brief Summary (1-2 Sentences)
In the case study, *The Right to Be an Exception to a Data-Driven Rule*, authors Sarah Cen and Manish Raghaven discuss an underrepresented but important perspective on the correctness of data-driven decision making. While the focus of data scientists continues to be eclipsed by accuracy metrics, the question remains on what to do with the inevitable exceptions, who, however rare, deserve certain rights as well. 

## Discussion Questions
**What is a data-driven rule, and what does it mean to be a data-driven exception? Is
an exception the same as an error?**

According to the article, a data-driven rule is some predicate for a decision made by a model; for example, a model might learn that if the ground is wet, the weather is probably rainy. I think that, for a lot of complex models, the precise rules the model builds are too complex to determine by a human. However, I can connect this to decision trees, which are a certain kind of model that I learned about in my Algorithms for Decision Making course. These models literally build a tree that branches based on the input into every possible decision. 

It seems that while exceptions are a component of error, they are not equivalent. Error is often expressed in terms of metrics like accuracy or specificity, and an exception -- a misclassification -- will naturally contribute to the amount of error observed in these metrics. However, the distinction seems to be that exceptions are individual, while error is aggregate; the article argues that, even if the individual exception is rare (error is low), that exception is still important. This is a little bit like our federal government, where congressional seats are allocated based on population (the house) AND individual states (the senate). Both perspectives are important.

**In addition to those listed above, what other factors differentiate data-driven decisions
from human ones?**

The article emphasizes that human decisions are "diverse," which is to say that by focusing or prioritizing seemingly arbitrary things, we humans can be more inclusive of the things that make each other unique. However, I think is just a nicer way of pointing out that humans have biases which are independent of data, while models can only be biased if the data is biased. What's interesting about that is how bias is not always such a bad thing; I think that by framing it as "diverse decision making," the article reveals an often-overlooked positive side to bias. Still, bias is generally problematic.

What I think is truly valuable about human decisions is faith: not religious faith, but rather pursuit of the absurd, in the manner described by Kierkegaard in *Fear and Trembling*. Even if, by all accounts, even after factoring in individuality and uncertainty, it is ill-advised to let a certain person out on parole, a human being may just do it anyways out of good will and good faith. Such a decision could prove harmful from a utilitarian perspective, but this irrational hope -- its own sort of bias I would say -- is what makes us so fundementally different from machine decisions. 

**Beyond what is discussed above, what are some of the benefits and downsides of individualization?**

One downside that the article doesn't really mention is interpretability. Models are described as being opaque, but it goes unacknowledged that more complex models are even more difficult to understand. A simple model which only accounts for a few variables may produce more exceptions, but it's easier for a human to determine how those exceptions came about.

Beyond that, I wonder if having such an individual-forward view poses too much of a threat to accuracy. I do think that this perspective is generally under represented among data scientists, but, as always, it is difficult to balance protecting the individual with protecting the collective. Finally, the article does mention privacy issues, but I think it's worth emphasizing that, if models are using sensitive, individualizing information to determine things like interest rates or insurance premiums, decisions that do not leave out many exceptions might not be such a desirable thing.

**Why is uncertainty so critical to the right to be an exception? When the stakes are
high (e.g., in criminal sentencing), is there any evaluation metric (e.g., accuracy) that
can justify the use of a data-driven rule without the consideration of uncertainty?**

Uncertainty is obviously critical to the right to be an exception because the universe is chaotic and random. Imagine that the ground was wet, there was no sprinkler nearby, the dew point was low, and there were clouds in the sky; it could still be that a flock of birds happened to synchronously poop on that patch of ground to make it wet, and the model would be wrong to say it was raining. However, what bothers me about focusing on uncertainty is that this problem is not unique to data-driven decisions or rules. When a judge decides to declare a certain sentence based on human reasoning, perhaps empirical, perhaps a priori, they are just as susceptible to uncertainty as the model is. 


## New Discussion Question
**How should this theory on the right to be an exception be applied to regression tasks? That is, how do you think about exceptions quantitatively?**

The article only focuses on classification tasks, but quantitative decisions bear the same weight with additional complexity. For example, a model might be used to decide how much federal grant money to give a student for their education based on their perceived need. Such a model would probably consider things like family income, relationships, and the demographic qualities of the applicant. Nevertheless, a student could have wealthy parents from which they are estranged, for example. This student would present an exception to the model, but to what extent? 

I believe this question forces us to reconsider the three components of data-driven rules from the article. It also requires a new methodology for adjustment based on those components, rather than simply making the decision or not.

## Brief Reflection
Throughout the activity, I was a little confused as to how this publication represents a case study. It never really focused on a particular event or situation like I expected it would. Nonetheless, it presented a perspective that I genuinely had not considered, and I think that I will be a better data scientist for it. 
